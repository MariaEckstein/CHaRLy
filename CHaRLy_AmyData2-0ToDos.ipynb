{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "* Do people perform better who noticed the rule switches (questionnaire)? Who counted the number of distinct rules correctly? \n",
    "* Split blocks into pre-star and post-star blocks => can I predict whether the star will be found on this block based on RT zigzag, i.e., exploration quality?\n",
    "* Rerun zigzag analyses using all_data_w; organize code\n",
    "    * (rt1 - rt2) / (rt1 + rt2) ((instead of sum(rts); to have a clean measure of individual 2-key sequences)\n",
    "    * To assess learning simple sequences, maybe just rt1 (rt3), not rt0-rt1?\n",
    "* Do participants explore complex sequences on the basis of simpler sequences?\n",
    "    * Ratio of individual actions / all actions and 2-key sequences / all actions, over time? Or 2-key sequences / individual actions?\n",
    "    * Does the ratio of 2-key sequences predict star discovery?\n",
    "    * Is it correlated with overall performance? With RT zigzag?\n",
    "* Do participants learn simple sequences *before* complex sequences?\n",
    "    * Plot frequency of 2-key sequences and frequency of stars (or cumulative number of 2-key sequences and stars) -> Bulk of 2-key sequences before bulk of stars, per block?\n",
    "* Discovery\n",
    "    * of 2-key sequences -> drop in within-sequence RTs (0&1 / 2&3)\n",
    "    * of 4-key sequences -> drop in between-sequences RTs (1&2)\n",
    "* Differences between high and low transfer\n",
    "    * Changes in RT patterns: High -> longer rt0 and rt2; low -> longer rt1 and rt3, especially for changed 2-key sequences\n",
    "* Trials in which the 2-key sequence all of a sudden stops working -> how do RTs change? what do people do after? explore more?\n",
    "* Read papers to come up with more ideas\n",
    "* Can I predict transfer performance from learning patterns?\n",
    "    * Little RT zigzag at the end -> Petrified building blocks, which are hard to unlearn -> Bad performance in low transfer\n",
    "    * Little RT zigzag at the end -> Petrified building blocks, which are stable and present -> Good performance in high transfer\n",
    "* How to set up the classical regression (predicting choices from previous choices and outcomes)?\n",
    "* Baseline computational model: random number generator (OR strategic exploration); until it hits a sequence, then repeats this as long as it works\n",
    "* Test this idea: Random exploration = no RT zigzag; searching for middle-layer items = heavy RT zigzag; using middle-layer items during exploration = heavy RT zigzag; found goal stars & exploiting them = no zigzag any more\n",
    "* Figure out what I was capturing in the old way calculating zigzag\n",
    "* Find better alignment points (like trial_tofirstdiscovery)\n",
    "* Go through comments in slides\n",
    "* Try out new ways of quantifying zigzag (see slides)\n",
    "* Do stats next (put phaseNum as a covariate)\n",
    "* Does number of executing non-sequences decrease over time?\n",
    "\n",
    "# In Progress\n",
    "\n",
    "\n",
    "# Done\n",
    "* CHECK Talk to Aram\n",
    "    * CHECK Want to continue? Your tasks will be ...\n",
    "* CHECK Look at block order column\n",
    "* CHECK Add question to qualtrix: Did you use pen & paper or other device?\n",
    "* CHECK Add star iteration (star 1, 2, ..., 9)\n",
    "* CHECK Add block order column (high_low or low_high?)\n",
    "* RT patterns when 2 subgoals were activated, vs 1 sub-goal (first half vs second half vs middle), vs no sub-goal\n",
    "* Split up into several notebooks\n",
    "* Compare star 1 high-transfer and star 1 low-transfer => have the same number of switched-out items\n",
    "* Figure out why stars differ in difficulty\n",
    "* Add more group-level analyses\n",
    "* Z-score rt_zigzag within blocks (avoid capturing just absolute RT differences over time)\n",
    "* Check mTurk exclusion criterion and update here in the code when finding chance-performers (25?)\n",
    "* Are the same number of participants in PhaseNum 1 and phaseNum 2? -> might account for differences because more people get low second, i.e., with more training\n",
    "* Plot 4 subtrial RTs seperately for when middle-layer items appears vs not -> affects RT3?\n",
    "* Look RT2 - RT3 -> zigzag\n",
    "* Compare zigzagging between 4-key and 3-key stars -> less zigzag in 4-key stars because participants do not learn them hierarchically?\n",
    "* Compare trials where something appears vs not -> are RTs different? do people notice that something appeared?\n",
    "* Try z-scoring RTs within trials?\n",
    "* What happens once participants discover a middle-layer item? Repeat it more often? Change in zigzag? How does it impact future choices?\n",
    "* log RTs\n",
    "* Count all groups (hands, order)\n",
    "* Compare the same repetition between the star presented first and the star presented second -> in high transfer, the second star does not benefit from the first, but in low transfer, it does\n",
    "* {New notebook}: Load questionnaire, relate subject IDs, look at differences\n",
    "    * Make sure which hand they use (questionnaire) doens't impact data\n",
    "    * Add qualtrix IDs (6-digit numbers)\n",
    "* Exclude participants who used pen & paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
