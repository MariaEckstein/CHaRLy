{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "## Concrete\n",
    "* RT patterns when 2 subgoals were activated, vs 1 sub-goal (first half vs second half vs middle), vs no sub-goal\n",
    "* Split blocks into pre-star and post-star blocks => can I predict whether the star will be found on this block based on RT zigzag, i.e., exploration quality?\n",
    "* Split up into several notebooks\n",
    "* Compare star 1 high-transfer and star 1 low-transfer => have the same number of switched-out items\n",
    "* Figure out why stars differ in difficulty\n",
    "* Add more group-level analyses\n",
    "* Z-score rt_zigzag within blocks (avoid capturing just absolute RT differences over time)\n",
    "* {New notebook}: Load questionnaire, relate subject IDs, look at differences\n",
    "    * Do people perform better who noticed the rule switches (questionnaire)? Who counted the number of distinct rules correctly? \n",
    "    * Make sure which hand they use (questionnaire) doens't impact data\n",
    "    * Exclude participant who used pen & paper\n",
    "    * Add qualtrix IDs (6-digit numbers)\n",
    "* CHECK Talk to Aram\n",
    "    * CHECK Want to continue? Your tasks will be ...\n",
    "* CHECK Look at block order column\n",
    "* CHECK Add question to qualtrix: Did you use pen & paper or other device?\n",
    "* CHECK Add star iteration (star 1, 2, ..., 9)\n",
    "* CHECK Add block order column (high_low or low_high?)\n",
    "\n",
    "## Abstract\n",
    "* Read papers to come up with more ideas!!!\n",
    "* Can I predict transfer performance from learning patterns?\n",
    "    * Little RT zigzag at the end -> Petrified building blocks, which are hard to unlearn -> Bad performance in low transfer\n",
    "    * Little RT zigzag at the end -> Petrified building blocks, which are stable and present -> Good performance in high transfer\n",
    "* How to set up the classical regression (predicting choices from previous choices and outcomes)?\n",
    "* Check mTurk exclusion criterion and update here in the code when finding chance-performers (25?)\n",
    "* Baseline computational model: random number generator (OR strategic exploration); until it hits a sequence, then repeats this as long as it works\n",
    "* Test this idea: Random exploration = no RT zigzag; searching for middle-layer items = heavy RT zigzag; using middle-layer items during exploration = heavy RT zigzag; found goal stars & exploiting them = no zigzag any more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
